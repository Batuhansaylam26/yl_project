accelerator: auto
alias: null
batch_size: 64
callbacks:
- !!python/object:pytorch_lightning.callbacks.early_stopping.EarlyStopping
  _check_on_train_epoch_end: false
  best_score: !!python/object/apply:torch._utils._rebuild_tensor_v2
  - !!python/object/apply:torch.storage._load_from_bytes
    - !!binary |
      gAKKCmz8nEb5IGqoUBkugAJN6QMugAJ9cQAoWBAAAABwcm90b2NvbF92ZXJzaW9ucQFN6QNYDQAA
      AGxpdHRsZV9lbmRpYW5xAohYCgAAAHR5cGVfc2l6ZXNxA31xBChYBQAAAHNob3J0cQVLAlgDAAAA
      aW50cQZLBFgEAAAAbG9uZ3EHSwR1dS6AAihYBwAAAHN0b3JhZ2VxAGN0b3JjaApGbG9hdFN0b3Jh
      Z2UKcQFYDwAAADE4NzY1MDc5MTM4MjQxNnECWAMAAABjcHVxA0sBTnRxBFEugAJdcQBYDwAAADE4
      NzY1MDc5MTM4MjQxNnEBYS4BAAAAAAAAAAAAgH8=
  - 0
  - !!python/tuple []
  - !!python/tuple []
  - false
  - !!python/object/apply:collections.OrderedDict
    - []
  check_finite: true
  divergence_threshold: null
  log_rank_zero_only: false
  min_delta: -0.0001
  mode: min
  monitor: valid_loss
  patience: 10
  stopped_epoch: 0
  stopping_reason: !!python/object/apply:pytorch_lightning.callbacks.early_stopping.EarlyStoppingReason
  - 0
  stopping_reason_message: null
  stopping_threshold: null
  strict: true
  verbose: true
  wait_count: 0
- !!python/object:pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint
  _defer_save_until_validation: false
  _enable_version_counter: true
  _every_n_epochs: 1
  _every_n_train_steps: 0
  _fs: !!python/object/apply:fsspec.spec.make_instance
  - !!python/name:fsspec.implementations.local.LocalFileSystem ''
  - !!python/tuple []
  - {}
  _last_checkpoint_saved: ''
  _last_global_step_saved: 0
  _last_time_checked: null
  _save_on_train_epoch_end: null
  _train_time_interval: null
  auto_insert_metric_name: true
  best_k_models: {}
  best_model_path: ''
  best_model_score: null
  current_score: null
  dirpath: /workspaces/yl_project/checkpoints
  filename: best-TimesNet-ep0_step0{epoch:02d}-{valid_loss:.4f}
  kth_best_model_path: ''
  kth_value: !!python/object/apply:torch._utils._rebuild_tensor_v2
  - !!python/object/apply:torch.storage._load_from_bytes
    - !!binary |
      gAKKCmz8nEb5IGqoUBkugAJN6QMugAJ9cQAoWBAAAABwcm90b2NvbF92ZXJzaW9ucQFN6QNYDQAA
      AGxpdHRsZV9lbmRpYW5xAohYCgAAAHR5cGVfc2l6ZXNxA31xBChYBQAAAHNob3J0cQVLAlgDAAAA
      aW50cQZLBFgEAAAAbG9uZ3EHSwR1dS6AAihYBwAAAHN0b3JhZ2VxAGN0b3JjaApGbG9hdFN0b3Jh
      Z2UKcQFYDwAAADE4NzY1MDc5MTMzNjQ4MHECWAMAAABjcHVxA0sBTnRxBFEugAJdcQBYDwAAADE4
      NzY1MDc5MTMzNjQ4MHEBYS4BAAAAAAAAAAAAgH8=
  - 0
  - !!python/tuple []
  - !!python/tuple []
  - false
  - !!python/object/apply:collections.OrderedDict
    - []
  last_model_path: ''
  mode: min
  monitor: valid_loss
  save_last: null
  save_on_exception: false
  save_top_k: 1
  save_weights_only: false
  verbose: true
conv_hidden_size: 16
dataloader_kwargs: null
drop_last_loader: false
dropout: 0.33063949289933825
early_stop_patience_steps: 10
enable_checkpointing: true
enable_model_summary: true
enable_progress_bar: true
encoder_layers: 4
exclude_insample_y: false
futr_exog_list:
- U
h: 20
h_train: 1
hidden_size: 32
hist_exog_list: null
inference_input_size: &id001 !!python/object/apply:numpy._core.multiarray.scalar
- !!python/object/apply:numpy.dtype
  args:
  - i8
  - false
  - true
  state: !!python/tuple
  - 3
  - <
  - null
  - null
  - null
  - -1
  - -1
  - 0
- !!binary |
  /AAAAAAAAAA=
inference_windows_batch_size: 256
input_size: *id001
learning_rate: 0.0001
logger: null
loss: !!python/object:neuralforecast.losses.pytorch.MSE
  _backward_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _backward_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _buffers: {}
  _forward_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _forward_hooks_always_called: !!python/object/apply:collections.OrderedDict
  - []
  _forward_hooks_with_kwargs: !!python/object/apply:collections.OrderedDict
  - []
  _forward_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _forward_pre_hooks_with_kwargs: !!python/object/apply:collections.OrderedDict
  - []
  _is_full_backward_hook: null
  _load_state_dict_post_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _load_state_dict_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _modules: {}
  _non_persistent_buffers_set: !!set {}
  _parameters: {}
  _state_dict_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _state_dict_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  horizon_weight: null
  is_distribution_output: false
  output_names:
  - ''
  outputsize_multiplier: 1
  training: true
lr_scheduler: !!python/name:torch.optim.lr_scheduler.CosineAnnealingLR ''
lr_scheduler_kwargs:
  T_max: 10
max_steps: 250
n_samples: 100
n_series: 1
num_kernels: 5
num_lr_decays: -1
optimizer: !!python/name:torch.optim.adadelta.Adadelta ''
optimizer_kwargs:
  lr: 0.001
  rho: 0.75
random_seed: 26
scaler_type: standard
start_padding_enabled: false
stat_exog_list: null
step_size: 1
top_k: 4
training_data_availability_threshold: 0.0
val_check_steps: 10
valid_batch_size: null
valid_loss: !!python/object:neuralforecast.losses.pytorch.MSE
  _backward_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _backward_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _buffers: {}
  _forward_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _forward_hooks_always_called: !!python/object/apply:collections.OrderedDict
  - []
  _forward_hooks_with_kwargs: !!python/object/apply:collections.OrderedDict
  - []
  _forward_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _forward_pre_hooks_with_kwargs: !!python/object/apply:collections.OrderedDict
  - []
  _is_full_backward_hook: null
  _load_state_dict_post_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _load_state_dict_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _modules: {}
  _non_persistent_buffers_set: !!set {}
  _parameters: {}
  _state_dict_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _state_dict_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  horizon_weight: null
  is_distribution_output: false
  output_names:
  - ''
  outputsize_multiplier: 1
  training: true
windows_batch_size: 64
