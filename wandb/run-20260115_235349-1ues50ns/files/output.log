[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
`Trainer(val_check_interval=1)` was configured so validation will run after every batch.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py:625: UserWarning: ignoring learning rate passed in optimizer_kwargs, using the model's learning rate
  warnings.warn(
[33m[W 2026-01-15 23:53:51,452][0m Trial 0 failed with parameters: {'input_size': 24, 'hidden_size': 256, 'dropout': 0.031997647880328994, 'conv_hidden_size': 16, 'top_k': 5, 'num_kernels': 8, 'encoder_layers': 4, 'batch_size': 32, 'windows_batch_size': 1024} because of the following error: TypeError("'<=' not supported between instances of 'float' and 'Float'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 602, in _fit
    trainer.fit(model, datamodule=datamodule)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 584, in fit
    call._call_and_handle_interrupt(
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 630, in _fit_impl
    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1053, in _run
    self.strategy.setup(self)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 159, in setup
    self.setup_optimizers(trainer)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 180, in _init_optimizers_and_lr_schedulers
    optim_conf = call._call_lightning_module_hook(model.trainer, "configure_optimizers", pl_module=model)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 629, in configure_optimizers
    optimizer = self.optimizer(params=self.parameters(), **optimizer_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/optim/adadelta.py", line 44, in __init__
    if not 0.0 <= lr:
           ^^^^^^^^^
TypeError: '<=' not supported between instances of 'float' and 'Float'
[33m[W 2026-01-15 23:53:51,453][0m Trial 0 failed with value None.[0m
Error training TimesNet: '<=' not supported between instances of 'float' and 'Float'
Step: 0 | Action: 0 (TimesNet) | Reward: -1.000000

======================================================================
Step 2/10: Training VanillaTransformer
======================================================================
[32m[I 2026-01-15 23:53:51,479][0m A new study created in memory with name: no-name-141ba51b-3b54-4682-9e9f-88eb3dc76507[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:51,488][0m Trial 0 failed with parameters: {'input_size': 96, 'nhead': 4, 'num_encoder_layers': 3, 'num_decoder_layers': 1, 'batch_size': 128, 'scaler_type': 'robust'} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'
[33m[W 2026-01-15 23:53:51,488][0m Trial 0 failed with value None.[0m
Error training VanillaTransformer: Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'
Step: 1 | Action: 1 (VanillaTransformer) | Reward: -1.000000

======================================================================
Step 3/10: Training GRU
======================================================================
[32m[I 2026-01-15 23:53:51,512][0m A new study created in memory with name: no-name-f3daea79-e45b-47f7-a183-f47948da7885[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:51,515][0m Trial 0 failed with parameters: {'input_size': 48, 'hidden_size': 64, 'num_layers': 3, 'batch_size': 64} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
[33m[W 2026-01-15 23:53:51,516][0m Trial 0 failed with value None.[0m
Error training GRU: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
Step: 2 | Action: 2 (GRU) | Reward: -1.000000

======================================================================
Step 4/10: Training LSTM
======================================================================
[32m[I 2026-01-15 23:53:51,535][0m A new study created in memory with name: no-name-543342e8-29a9-41fd-9121-61b28b2978c3[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:51,538][0m Trial 0 failed with parameters: {'input_size': 96, 'hidden_size': 32, 'num_layers': 2, 'batch_size': 32} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
[33m[W 2026-01-15 23:53:51,539][0m Trial 0 failed with value None.[0m
Error training LSTM: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
Step: 3 | Action: 3 (LSTM) | Reward: -1.000000

======================================================================
Step 5/10: Training KAN
======================================================================
[32m[I 2026-01-15 23:53:51,556][0m A new study created in memory with name: no-name-110aa506-fc17-4d28-a0fc-494a69520b22[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py:625: UserWarning: ignoring learning rate passed in optimizer_kwargs, using the model's learning rate
  warnings.warn(
[33m[W 2026-01-15 23:53:51,587][0m Trial 0 failed with parameters: {'input_size': 72, 'hidden_size': 128, 'grid_size': 10, 'batch_size': 64, 'spline_order': 2, 'scaler_type': 'minmax'} because of the following error: MisconfigurationException('The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}').[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 602, in _fit
    trainer.fit(model, datamodule=datamodule)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 584, in fit
    call._call_and_handle_interrupt(
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 630, in _fit_impl
    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1053, in _run
    self.strategy.setup(self)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 159, in setup
    self.setup_optimizers(trainer)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 190, in _init_optimizers_and_lr_schedulers
    _configure_schedulers_automatic_opt(lr_schedulers, monitor)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 278, in _configure_schedulers_automatic_opt
    raise MisconfigurationException(
lightning_fabric.utilities.exceptions.MisconfigurationException: The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}
[33m[W 2026-01-15 23:53:51,588][0m Trial 0 failed with value None.[0m
Error training KAN: The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}
Step: 4 | Action: 4 (KAN) | Reward: -1.000000

======================================================================
Step 6/10: Training TimesNet
======================================================================
[32m[I 2026-01-15 23:53:51,606][0m A new study created in memory with name: no-name-f0e8b53d-2783-4ad4-a4ea-3670af4f3872[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
`Trainer(val_check_interval=1)` was configured so validation will run after every batch.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py:625: UserWarning: ignoring learning rate passed in optimizer_kwargs, using the model's learning rate
  warnings.warn(
[33m[W 2026-01-15 23:53:51,629][0m Trial 0 failed with parameters: {'input_size': 48, 'hidden_size': 64, 'dropout': 0.39764692834219373, 'conv_hidden_size': 16, 'top_k': 3, 'num_kernels': 6, 'encoder_layers': 3, 'batch_size': 64, 'windows_batch_size': 128} because of the following error: TypeError("'<=' not supported between instances of 'float' and 'Float'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 602, in _fit
    trainer.fit(model, datamodule=datamodule)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 584, in fit
    call._call_and_handle_interrupt(
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 630, in _fit_impl
    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1053, in _run
    self.strategy.setup(self)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 159, in setup
    self.setup_optimizers(trainer)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 180, in _init_optimizers_and_lr_schedulers
    optim_conf = call._call_lightning_module_hook(model.trainer, "configure_optimizers", pl_module=model)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 629, in configure_optimizers
    optimizer = self.optimizer(params=self.parameters(), **optimizer_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/optim/adadelta.py", line 44, in __init__
    if not 0.0 <= lr:
           ^^^^^^^^^
TypeError: '<=' not supported between instances of 'float' and 'Float'
[33m[W 2026-01-15 23:53:51,629][0m Trial 0 failed with value None.[0m
Error training TimesNet: '<=' not supported between instances of 'float' and 'Float'
Step: 5 | Action: 0 (TimesNet) | Reward: -1.000000

======================================================================
Step 7/10: Training VanillaTransformer
======================================================================
[32m[I 2026-01-15 23:53:51,647][0m A new study created in memory with name: no-name-3014c8ad-8ae5-4632-b744-af2097e8ca0e[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:51,655][0m Trial 0 failed with parameters: {'input_size': 48, 'nhead': 8, 'num_encoder_layers': 2, 'num_decoder_layers': 2, 'batch_size': 16, 'scaler_type': 'minmax'} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'
[33m[W 2026-01-15 23:53:51,655][0m Trial 0 failed with value None.[0m
Error training VanillaTransformer: Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'
Step: 6 | Action: 1 (VanillaTransformer) | Reward: -1.000000

======================================================================
Step 8/10: Training GRU
======================================================================
[32m[I 2026-01-15 23:53:51,672][0m A new study created in memory with name: no-name-a01e86b6-ff92-4ec8-8925-561eb197df0e[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:51,676][0m Trial 0 failed with parameters: {'input_size': 96, 'hidden_size': 256, 'num_layers': 2, 'batch_size': 16} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
[33m[W 2026-01-15 23:53:51,676][0m Trial 0 failed with value None.[0m
Error training GRU: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
Step: 7 | Action: 2 (GRU) | Reward: -1.000000

======================================================================
Step 9/10: Training LSTM
======================================================================
[32m[I 2026-01-15 23:53:51,692][0m A new study created in memory with name: no-name-9d00430c-1d51-43a2-8fd3-758f3753b625[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:51,697][0m Trial 0 failed with parameters: {'input_size': 72, 'hidden_size': 256, 'num_layers': 1, 'batch_size': 16} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
[33m[W 2026-01-15 23:53:51,697][0m Trial 0 failed with value None.[0m
Error training LSTM: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
Step: 8 | Action: 3 (LSTM) | Reward: -1.000000

======================================================================
Step 10/10: Training KAN
======================================================================
[32m[I 2026-01-15 23:53:51,717][0m A new study created in memory with name: no-name-8e2827aa-979c-49b6-899a-cc031de72805[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py:625: UserWarning: ignoring learning rate passed in optimizer_kwargs, using the model's learning rate
  warnings.warn(
[33m[W 2026-01-15 23:53:51,725][0m Trial 0 failed with parameters: {'input_size': 96, 'hidden_size': 32, 'grid_size': 5, 'batch_size': 64, 'spline_order': 3, 'scaler_type': 'robust'} because of the following error: MisconfigurationException('The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}').[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 602, in _fit
    trainer.fit(model, datamodule=datamodule)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 584, in fit
    call._call_and_handle_interrupt(
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 630, in _fit_impl
    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1053, in _run
    self.strategy.setup(self)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 159, in setup
    self.setup_optimizers(trainer)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 190, in _init_optimizers_and_lr_schedulers
    _configure_schedulers_automatic_opt(lr_schedulers, monitor)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 278, in _configure_schedulers_automatic_opt
    raise MisconfigurationException(
lightning_fabric.utilities.exceptions.MisconfigurationException: The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}
[33m[W 2026-01-15 23:53:51,726][0m Trial 0 failed with value None.[0m
Error training KAN: The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}
Step: 9 | Action: 4 (KAN) | Reward: -1.000000
HenÃ¼z sonuÃ§ yok!

=== Episode 2/5 ===

======================================================================
Environment Reset
======================================================================


======================================================================
Step 1/10: Training TimesNet
======================================================================
[32m[I 2026-01-15 23:53:51,757][0m A new study created in memory with name: no-name-eb4797ab-8d2e-4955-962a-0982ad780cb9[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
`Trainer(val_check_interval=1)` was configured so validation will run after every batch.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py:625: UserWarning: ignoring learning rate passed in optimizer_kwargs, using the model's learning rate
  warnings.warn(
[33m[W 2026-01-15 23:53:52,080][0m Trial 0 failed with parameters: {'input_size': 24, 'hidden_size': 256, 'dropout': 0.4781827149761265, 'conv_hidden_size': 128, 'top_k': 4, 'num_kernels': 6, 'encoder_layers': 2, 'batch_size': 64, 'windows_batch_size': 128} because of the following error: TypeError("'<=' not supported between instances of 'float' and 'Float'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 602, in _fit
    trainer.fit(model, datamodule=datamodule)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 584, in fit
    call._call_and_handle_interrupt(
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 630, in _fit_impl
    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1053, in _run
    self.strategy.setup(self)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 159, in setup
    self.setup_optimizers(trainer)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 180, in _init_optimizers_and_lr_schedulers
    optim_conf = call._call_lightning_module_hook(model.trainer, "configure_optimizers", pl_module=model)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 629, in configure_optimizers
    optimizer = self.optimizer(params=self.parameters(), **optimizer_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/optim/adadelta.py", line 44, in __init__
    if not 0.0 <= lr:
           ^^^^^^^^^
TypeError: '<=' not supported between instances of 'float' and 'Float'
[33m[W 2026-01-15 23:53:52,081][0m Trial 0 failed with value None.[0m
Error training TimesNet: '<=' not supported between instances of 'float' and 'Float'
Step: 10 | Action: 0 (TimesNet) | Reward: -1.000000

======================================================================
Step 2/10: Training VanillaTransformer
======================================================================
[32m[I 2026-01-15 23:53:52,101][0m A new study created in memory with name: no-name-066f55a4-9424-4ba1-9b1f-dac86833d3c5[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:52,110][0m Trial 0 failed with parameters: {'input_size': 48, 'nhead': 2, 'num_encoder_layers': 3, 'num_decoder_layers': 2, 'batch_size': 16, 'scaler_type': 'robust'} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'
[33m[W 2026-01-15 23:53:52,110][0m Trial 0 failed with value None.[0m
Error training VanillaTransformer: Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'
Step: 11 | Action: 1 (VanillaTransformer) | Reward: -1.000000

======================================================================
Step 3/10: Training GRU
======================================================================
[32m[I 2026-01-15 23:53:52,130][0m A new study created in memory with name: no-name-1eff3645-e87a-4c5e-b614-4009cca14f05[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:52,134][0m Trial 0 failed with parameters: {'input_size': 48, 'hidden_size': 256, 'num_layers': 2, 'batch_size': 64} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
[33m[W 2026-01-15 23:53:52,134][0m Trial 0 failed with value None.[0m
Error training GRU: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
Step: 12 | Action: 2 (GRU) | Reward: -1.000000

======================================================================
Step 4/10: Training LSTM
======================================================================
[32m[I 2026-01-15 23:53:52,153][0m A new study created in memory with name: no-name-8e33c6f0-6b3c-462f-8411-ab5032e99eae[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:52,156][0m Trial 0 failed with parameters: {'input_size': 24, 'hidden_size': 128, 'num_layers': 1, 'batch_size': 32} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
[33m[W 2026-01-15 23:53:52,157][0m Trial 0 failed with value None.[0m
Error training LSTM: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
Step: 13 | Action: 3 (LSTM) | Reward: -1.000000

======================================================================
Step 5/10: Training KAN
======================================================================
[32m[I 2026-01-15 23:53:52,175][0m A new study created in memory with name: no-name-15920489-9b8e-4077-ba7a-75dcb3544d83[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py:625: UserWarning: ignoring learning rate passed in optimizer_kwargs, using the model's learning rate
  warnings.warn(
[33m[W 2026-01-15 23:53:52,183][0m Trial 0 failed with parameters: {'input_size': 24, 'hidden_size': 32, 'grid_size': 15, 'batch_size': 16, 'spline_order': 4, 'scaler_type': 'robust'} because of the following error: MisconfigurationException('The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}').[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 602, in _fit
    trainer.fit(model, datamodule=datamodule)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 584, in fit
    call._call_and_handle_interrupt(
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 630, in _fit_impl
    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1053, in _run
    self.strategy.setup(self)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 159, in setup
    self.setup_optimizers(trainer)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 190, in _init_optimizers_and_lr_schedulers
    _configure_schedulers_automatic_opt(lr_schedulers, monitor)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 278, in _configure_schedulers_automatic_opt
    raise MisconfigurationException(
lightning_fabric.utilities.exceptions.MisconfigurationException: The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}
[33m[W 2026-01-15 23:53:52,183][0m Trial 0 failed with value None.[0m
Error training KAN: The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}
Step: 14 | Action: 4 (KAN) | Reward: -1.000000

======================================================================
Step 6/10: Training TimesNet
======================================================================
[32m[I 2026-01-15 23:53:52,200][0m A new study created in memory with name: no-name-f478e942-1366-4ba2-b003-d6f5404dc6c7[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
`Trainer(val_check_interval=1)` was configured so validation will run after every batch.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py:625: UserWarning: ignoring learning rate passed in optimizer_kwargs, using the model's learning rate
  warnings.warn(
[33m[W 2026-01-15 23:53:52,350][0m Trial 0 failed with parameters: {'input_size': 96, 'hidden_size': 256, 'dropout': 0.1984594199272196, 'conv_hidden_size': 64, 'top_k': 7, 'num_kernels': 6, 'encoder_layers': 2, 'batch_size': 128, 'windows_batch_size': 128} because of the following error: TypeError("'<=' not supported between instances of 'float' and 'Float'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 602, in _fit
    trainer.fit(model, datamodule=datamodule)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 584, in fit
    call._call_and_handle_interrupt(
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 630, in _fit_impl
    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1053, in _run
    self.strategy.setup(self)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 159, in setup
    self.setup_optimizers(trainer)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 180, in _init_optimizers_and_lr_schedulers
    optim_conf = call._call_lightning_module_hook(model.trainer, "configure_optimizers", pl_module=model)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 629, in configure_optimizers
    optimizer = self.optimizer(params=self.parameters(), **optimizer_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/optim/adadelta.py", line 44, in __init__
    if not 0.0 <= lr:
           ^^^^^^^^^
TypeError: '<=' not supported between instances of 'float' and 'Float'
[33m[W 2026-01-15 23:53:52,351][0m Trial 0 failed with value None.[0m
Error training TimesNet: '<=' not supported between instances of 'float' and 'Float'
Step: 15 | Action: 0 (TimesNet) | Reward: -1.000000

======================================================================
Step 7/10: Training VanillaTransformer
======================================================================
[32m[I 2026-01-15 23:53:52,369][0m A new study created in memory with name: no-name-e9bab796-a939-4017-9e79-cd484c82a308[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:52,377][0m Trial 0 failed with parameters: {'input_size': 24, 'nhead': 2, 'num_encoder_layers': 2, 'num_decoder_layers': 4, 'batch_size': 64, 'scaler_type': 'standard'} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'
[33m[W 2026-01-15 23:53:52,378][0m Trial 0 failed with value None.[0m
Error training VanillaTransformer: Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'
Step: 16 | Action: 1 (VanillaTransformer) | Reward: -1.000000

======================================================================
Step 8/10: Training GRU
======================================================================
[32m[I 2026-01-15 23:53:52,395][0m A new study created in memory with name: no-name-cf96bcea-9d1e-47bb-86b8-7c23a4c013d0[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:52,398][0m Trial 0 failed with parameters: {'input_size': 72, 'hidden_size': 128, 'num_layers': 2, 'batch_size': 16} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
[33m[W 2026-01-15 23:53:52,398][0m Trial 0 failed with value None.[0m
Error training GRU: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
Step: 17 | Action: 2 (GRU) | Reward: -1.000000

======================================================================
Step 9/10: Training LSTM
======================================================================
[32m[I 2026-01-15 23:53:52,415][0m A new study created in memory with name: no-name-19474ac9-38bf-4762-b7c2-deb7643d72fe[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:52,417][0m Trial 0 failed with parameters: {'input_size': 72, 'hidden_size': 64, 'num_layers': 3, 'batch_size': 32} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
[33m[W 2026-01-15 23:53:52,418][0m Trial 0 failed with value None.[0m
Error training LSTM: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
Step: 18 | Action: 3 (LSTM) | Reward: -1.000000

======================================================================
Step 10/10: Training KAN
======================================================================
[32m[I 2026-01-15 23:53:52,435][0m A new study created in memory with name: no-name-d8354ce9-bc50-4f34-a1ef-7c07b6ecf352[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py:625: UserWarning: ignoring learning rate passed in optimizer_kwargs, using the model's learning rate
  warnings.warn(
[33m[W 2026-01-15 23:53:52,464][0m Trial 0 failed with parameters: {'input_size': 72, 'hidden_size': 256, 'grid_size': 20, 'batch_size': 16, 'spline_order': 4, 'scaler_type': 'minmax'} because of the following error: MisconfigurationException('The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}').[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 602, in _fit
    trainer.fit(model, datamodule=datamodule)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 584, in fit
    call._call_and_handle_interrupt(
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 630, in _fit_impl
    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1053, in _run
    self.strategy.setup(self)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 159, in setup
    self.setup_optimizers(trainer)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 190, in _init_optimizers_and_lr_schedulers
    _configure_schedulers_automatic_opt(lr_schedulers, monitor)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 278, in _configure_schedulers_automatic_opt
    raise MisconfigurationException(
lightning_fabric.utilities.exceptions.MisconfigurationException: The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}
[33m[W 2026-01-15 23:53:52,464][0m Trial 0 failed with value None.[0m
Error training KAN: The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}
Step: 19 | Action: 4 (KAN) | Reward: -1.000000
HenÃ¼z sonuÃ§ yok!

=== Episode 3/5 ===

======================================================================
Environment Reset
======================================================================


======================================================================
Step 1/10: Training TimesNet
======================================================================
[32m[I 2026-01-15 23:53:52,482][0m A new study created in memory with name: no-name-de4a4612-96f5-4ee1-88ca-7b1bd40ec756[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
`Trainer(val_check_interval=1)` was configured so validation will run after every batch.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py:625: UserWarning: ignoring learning rate passed in optimizer_kwargs, using the model's learning rate
  warnings.warn(
[33m[W 2026-01-15 23:53:52,529][0m Trial 0 failed with parameters: {'input_size': 72, 'hidden_size': 256, 'dropout': 0.1782203045817679, 'conv_hidden_size': 32, 'top_k': 5, 'num_kernels': 5, 'encoder_layers': 2, 'batch_size': 64, 'windows_batch_size': 1024} because of the following error: TypeError("'<=' not supported between instances of 'float' and 'Float'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 602, in _fit
    trainer.fit(model, datamodule=datamodule)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 584, in fit
    call._call_and_handle_interrupt(
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 630, in _fit_impl
    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1053, in _run
    self.strategy.setup(self)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 159, in setup
    self.setup_optimizers(trainer)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 180, in _init_optimizers_and_lr_schedulers
    optim_conf = call._call_lightning_module_hook(model.trainer, "configure_optimizers", pl_module=model)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 629, in configure_optimizers
    optimizer = self.optimizer(params=self.parameters(), **optimizer_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/optim/adadelta.py", line 44, in __init__
    if not 0.0 <= lr:
           ^^^^^^^^^
TypeError: '<=' not supported between instances of 'float' and 'Float'
[33m[W 2026-01-15 23:53:52,530][0m Trial 0 failed with value None.[0m
Error training TimesNet: '<=' not supported between instances of 'float' and 'Float'
Step: 20 | Action: 0 (TimesNet) | Reward: -1.000000

======================================================================
Step 2/10: Training VanillaTransformer
======================================================================
[32m[I 2026-01-15 23:53:52,547][0m A new study created in memory with name: no-name-f6752493-e590-4cd6-870b-05fbce28996f[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:52,555][0m Trial 0 failed with parameters: {'input_size': 96, 'nhead': 8, 'num_encoder_layers': 1, 'num_decoder_layers': 3, 'batch_size': 128, 'scaler_type': 'minmax'} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'
[33m[W 2026-01-15 23:53:52,555][0m Trial 0 failed with value None.[0m
Error training VanillaTransformer: Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'
Step: 21 | Action: 1 (VanillaTransformer) | Reward: -1.000000

======================================================================
Step 3/10: Training GRU
======================================================================
[32m[I 2026-01-15 23:53:52,572][0m A new study created in memory with name: no-name-af236b0a-2351-4e4e-a4a7-ca839a004f9a[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:52,575][0m Trial 0 failed with parameters: {'input_size': 72, 'hidden_size': 64, 'num_layers': 3, 'batch_size': 128} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
[33m[W 2026-01-15 23:53:52,575][0m Trial 0 failed with value None.[0m
Error training GRU: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
Step: 22 | Action: 2 (GRU) | Reward: -1.000000

======================================================================
Step 4/10: Training LSTM
======================================================================
[32m[I 2026-01-15 23:53:52,592][0m A new study created in memory with name: no-name-411ed3d7-2235-4e9b-9f16-51a0e8aaf139[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:52,596][0m Trial 0 failed with parameters: {'input_size': 24, 'hidden_size': 256, 'num_layers': 3, 'batch_size': 16} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
[33m[W 2026-01-15 23:53:52,597][0m Trial 0 failed with value None.[0m
Error training LSTM: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
Step: 23 | Action: 3 (LSTM) | Reward: -1.000000

======================================================================
Step 5/10: Training KAN
======================================================================
[32m[I 2026-01-15 23:53:52,613][0m A new study created in memory with name: no-name-d14af764-1610-422e-9cbd-e4b727e3babd[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py:625: UserWarning: ignoring learning rate passed in optimizer_kwargs, using the model's learning rate
  warnings.warn(
[33m[W 2026-01-15 23:53:52,621][0m Trial 0 failed with parameters: {'input_size': 48, 'hidden_size': 32, 'grid_size': 5, 'batch_size': 64, 'spline_order': 4, 'scaler_type': 'standard'} because of the following error: MisconfigurationException('The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}').[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 602, in _fit
    trainer.fit(model, datamodule=datamodule)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 584, in fit
    call._call_and_handle_interrupt(
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 630, in _fit_impl
    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1053, in _run
    self.strategy.setup(self)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 159, in setup
    self.setup_optimizers(trainer)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 190, in _init_optimizers_and_lr_schedulers
    _configure_schedulers_automatic_opt(lr_schedulers, monitor)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 278, in _configure_schedulers_automatic_opt
    raise MisconfigurationException(
lightning_fabric.utilities.exceptions.MisconfigurationException: The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}
[33m[W 2026-01-15 23:53:52,621][0m Trial 0 failed with value None.[0m
Error training KAN: The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}
Step: 24 | Action: 4 (KAN) | Reward: -1.000000

======================================================================
Step 6/10: Training TimesNet
======================================================================
[32m[I 2026-01-15 23:53:52,639][0m A new study created in memory with name: no-name-8fdd3ecb-ee0f-43bb-aecd-15ec95b17bb4[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
`Trainer(val_check_interval=1)` was configured so validation will run after every batch.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py:625: UserWarning: ignoring learning rate passed in optimizer_kwargs, using the model's learning rate
  warnings.warn(
[33m[W 2026-01-15 23:53:52,668][0m Trial 0 failed with parameters: {'input_size': 96, 'hidden_size': 256, 'dropout': 0.35559058570318836, 'conv_hidden_size': 32, 'top_k': 3, 'num_kernels': 5, 'encoder_layers': 1, 'batch_size': 32, 'windows_batch_size': 1024} because of the following error: TypeError("'<=' not supported between instances of 'float' and 'Float'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 602, in _fit
    trainer.fit(model, datamodule=datamodule)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 584, in fit
    call._call_and_handle_interrupt(
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 630, in _fit_impl
    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1053, in _run
    self.strategy.setup(self)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 159, in setup
    self.setup_optimizers(trainer)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 180, in _init_optimizers_and_lr_schedulers
    optim_conf = call._call_lightning_module_hook(model.trainer, "configure_optimizers", pl_module=model)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 629, in configure_optimizers
    optimizer = self.optimizer(params=self.parameters(), **optimizer_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/optim/adadelta.py", line 44, in __init__
    if not 0.0 <= lr:
           ^^^^^^^^^
TypeError: '<=' not supported between instances of 'float' and 'Float'
[33m[W 2026-01-15 23:53:52,669][0m Trial 0 failed with value None.[0m
Error training TimesNet: '<=' not supported between instances of 'float' and 'Float'
Step: 25 | Action: 0 (TimesNet) | Reward: -1.000000

======================================================================
Step 7/10: Training VanillaTransformer
======================================================================
[32m[I 2026-01-15 23:53:52,686][0m A new study created in memory with name: no-name-824e12cb-7f4a-42d0-ab6b-31c17a54ddc0[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:52,692][0m Trial 0 failed with parameters: {'input_size': 24, 'nhead': 8, 'num_encoder_layers': 3, 'num_decoder_layers': 1, 'batch_size': 64, 'scaler_type': 'robust'} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'
[33m[W 2026-01-15 23:53:52,692][0m Trial 0 failed with value None.[0m
Error training VanillaTransformer: Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'
Step: 26 | Action: 1 (VanillaTransformer) | Reward: -1.000000

======================================================================
Step 8/10: Training GRU
======================================================================
[32m[I 2026-01-15 23:53:52,709][0m A new study created in memory with name: no-name-047eae8b-2f82-4c29-b1c2-e4ac78a86617[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:52,712][0m Trial 0 failed with parameters: {'input_size': 96, 'hidden_size': 256, 'num_layers': 3, 'batch_size': 32} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
[33m[W 2026-01-15 23:53:52,713][0m Trial 0 failed with value None.[0m
Error training GRU: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
Step: 27 | Action: 2 (GRU) | Reward: -1.000000

======================================================================
Step 9/10: Training LSTM
======================================================================
[32m[I 2026-01-15 23:53:52,731][0m A new study created in memory with name: no-name-91f52ee9-293c-4263-be48-311e502d2ece[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:52,733][0m Trial 0 failed with parameters: {'input_size': 96, 'hidden_size': 32, 'num_layers': 2, 'batch_size': 32} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
[33m[W 2026-01-15 23:53:52,733][0m Trial 0 failed with value None.[0m
Error training LSTM: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
Step: 28 | Action: 3 (LSTM) | Reward: -1.000000

======================================================================
Step 10/10: Training KAN
======================================================================
[32m[I 2026-01-15 23:53:52,750][0m A new study created in memory with name: no-name-9069a526-8d01-4e0a-b92b-c265e4f34b72[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py:625: UserWarning: ignoring learning rate passed in optimizer_kwargs, using the model's learning rate
  warnings.warn(
[33m[W 2026-01-15 23:53:52,760][0m Trial 0 failed with parameters: {'input_size': 96, 'hidden_size': 64, 'grid_size': 5, 'batch_size': 64, 'spline_order': 4, 'scaler_type': 'robust'} because of the following error: MisconfigurationException('The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}').[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 602, in _fit
    trainer.fit(model, datamodule=datamodule)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 584, in fit
    call._call_and_handle_interrupt(
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 630, in _fit_impl
    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1053, in _run
    self.strategy.setup(self)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 159, in setup
    self.setup_optimizers(trainer)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 190, in _init_optimizers_and_lr_schedulers
    _configure_schedulers_automatic_opt(lr_schedulers, monitor)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 278, in _configure_schedulers_automatic_opt
    raise MisconfigurationException(
lightning_fabric.utilities.exceptions.MisconfigurationException: The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}
[33m[W 2026-01-15 23:53:52,760][0m Trial 0 failed with value None.[0m
Error training KAN: The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}
Step: 29 | Action: 4 (KAN) | Reward: -1.000000
HenÃ¼z sonuÃ§ yok!

=== Episode 4/5 ===

======================================================================
Environment Reset
======================================================================


======================================================================
Step 1/10: Training TimesNet
======================================================================
[32m[I 2026-01-15 23:53:52,778][0m A new study created in memory with name: no-name-090a5a7c-974f-40b8-85fb-28f290350cae[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
`Trainer(val_check_interval=1)` was configured so validation will run after every batch.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py:625: UserWarning: ignoring learning rate passed in optimizer_kwargs, using the model's learning rate
  warnings.warn(
[33m[W 2026-01-15 23:53:52,863][0m Trial 0 failed with parameters: {'input_size': 48, 'hidden_size': 128, 'dropout': 0.09908413614672479, 'conv_hidden_size': 32, 'top_k': 4, 'num_kernels': 7, 'encoder_layers': 3, 'batch_size': 32, 'windows_batch_size': 256} because of the following error: TypeError("'<=' not supported between instances of 'float' and 'Float'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 602, in _fit
    trainer.fit(model, datamodule=datamodule)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 584, in fit
    call._call_and_handle_interrupt(
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 630, in _fit_impl
    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1053, in _run
    self.strategy.setup(self)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 159, in setup
    self.setup_optimizers(trainer)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 180, in _init_optimizers_and_lr_schedulers
    optim_conf = call._call_lightning_module_hook(model.trainer, "configure_optimizers", pl_module=model)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 629, in configure_optimizers
    optimizer = self.optimizer(params=self.parameters(), **optimizer_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/optim/adadelta.py", line 44, in __init__
    if not 0.0 <= lr:
           ^^^^^^^^^
TypeError: '<=' not supported between instances of 'float' and 'Float'
[33m[W 2026-01-15 23:53:52,863][0m Trial 0 failed with value None.[0m
Error training TimesNet: '<=' not supported between instances of 'float' and 'Float'
Step: 30 | Action: 0 (TimesNet) | Reward: -1.000000

======================================================================
Step 2/10: Training VanillaTransformer
======================================================================
[32m[I 2026-01-15 23:53:52,888][0m A new study created in memory with name: no-name-f1b22cf5-783a-43be-8320-ce892df5e9cf[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:52,897][0m Trial 0 failed with parameters: {'input_size': 24, 'nhead': 4, 'num_encoder_layers': 4, 'num_decoder_layers': 4, 'batch_size': 16, 'scaler_type': 'standard'} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'
[33m[W 2026-01-15 23:53:52,897][0m Trial 0 failed with value None.[0m
Error training VanillaTransformer: Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'
Step: 31 | Action: 1 (VanillaTransformer) | Reward: -1.000000

======================================================================
Step 3/10: Training GRU
======================================================================
[32m[I 2026-01-15 23:53:52,913][0m A new study created in memory with name: no-name-fc7d4eca-7785-4521-8c43-dc76c5165d7e[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:52,917][0m Trial 0 failed with parameters: {'input_size': 96, 'hidden_size': 32, 'num_layers': 2, 'batch_size': 16} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
[33m[W 2026-01-15 23:53:52,917][0m Trial 0 failed with value None.[0m
Error training GRU: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
Step: 32 | Action: 2 (GRU) | Reward: -1.000000

======================================================================
Step 4/10: Training LSTM
======================================================================
[32m[I 2026-01-15 23:53:52,933][0m A new study created in memory with name: no-name-4442c4d1-192c-4fdb-8a16-dcc074011cdf[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:52,937][0m Trial 0 failed with parameters: {'input_size': 24, 'hidden_size': 256, 'num_layers': 3, 'batch_size': 32} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
[33m[W 2026-01-15 23:53:52,937][0m Trial 0 failed with value None.[0m
Error training LSTM: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
Step: 33 | Action: 3 (LSTM) | Reward: -1.000000

======================================================================
Step 5/10: Training KAN
======================================================================
[32m[I 2026-01-15 23:53:52,953][0m A new study created in memory with name: no-name-337c706b-60f0-4795-92c9-67acb5d6b8af[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py:625: UserWarning: ignoring learning rate passed in optimizer_kwargs, using the model's learning rate
  warnings.warn(
[33m[W 2026-01-15 23:53:52,962][0m Trial 0 failed with parameters: {'input_size': 24, 'hidden_size': 64, 'grid_size': 15, 'batch_size': 64, 'spline_order': 4, 'scaler_type': 'robust'} because of the following error: MisconfigurationException('The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}').[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 602, in _fit
    trainer.fit(model, datamodule=datamodule)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 584, in fit
    call._call_and_handle_interrupt(
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 630, in _fit_impl
    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1053, in _run
    self.strategy.setup(self)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 159, in setup
    self.setup_optimizers(trainer)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 190, in _init_optimizers_and_lr_schedulers
    _configure_schedulers_automatic_opt(lr_schedulers, monitor)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 278, in _configure_schedulers_automatic_opt
    raise MisconfigurationException(
lightning_fabric.utilities.exceptions.MisconfigurationException: The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}
[33m[W 2026-01-15 23:53:52,963][0m Trial 0 failed with value None.[0m
Error training KAN: The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}
Step: 34 | Action: 4 (KAN) | Reward: -1.000000

======================================================================
Step 6/10: Training TimesNet
======================================================================
[32m[I 2026-01-15 23:53:52,979][0m A new study created in memory with name: no-name-435330b0-4067-4dcb-944e-b152f0b6c0ba[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
`Trainer(val_check_interval=1)` was configured so validation will run after every batch.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py:625: UserWarning: ignoring learning rate passed in optimizer_kwargs, using the model's learning rate
  warnings.warn(
[33m[W 2026-01-15 23:53:52,998][0m Trial 0 failed with parameters: {'input_size': 72, 'hidden_size': 128, 'dropout': 0.2937462788381435, 'conv_hidden_size': 32, 'top_k': 5, 'num_kernels': 5, 'encoder_layers': 1, 'batch_size': 32, 'windows_batch_size': 512} because of the following error: TypeError("'<=' not supported between instances of 'float' and 'Float'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 602, in _fit
    trainer.fit(model, datamodule=datamodule)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 584, in fit
    call._call_and_handle_interrupt(
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 630, in _fit_impl
    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1053, in _run
    self.strategy.setup(self)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 159, in setup
    self.setup_optimizers(trainer)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 180, in _init_optimizers_and_lr_schedulers
    optim_conf = call._call_lightning_module_hook(model.trainer, "configure_optimizers", pl_module=model)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 629, in configure_optimizers
    optimizer = self.optimizer(params=self.parameters(), **optimizer_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/optim/adadelta.py", line 44, in __init__
    if not 0.0 <= lr:
           ^^^^^^^^^
TypeError: '<=' not supported between instances of 'float' and 'Float'
[33m[W 2026-01-15 23:53:52,998][0m Trial 0 failed with value None.[0m
Error training TimesNet: '<=' not supported between instances of 'float' and 'Float'
Step: 35 | Action: 0 (TimesNet) | Reward: -1.000000

======================================================================
Step 7/10: Training VanillaTransformer
======================================================================
[32m[I 2026-01-15 23:53:53,015][0m A new study created in memory with name: no-name-e10b881f-be69-459f-890a-997472b12e88[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:53,022][0m Trial 0 failed with parameters: {'input_size': 48, 'nhead': 8, 'num_encoder_layers': 4, 'num_decoder_layers': 1, 'batch_size': 16, 'scaler_type': 'minmax'} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'
[33m[W 2026-01-15 23:53:53,022][0m Trial 0 failed with value None.[0m
Error training VanillaTransformer: Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'
Step: 36 | Action: 1 (VanillaTransformer) | Reward: -1.000000

======================================================================
Step 8/10: Training GRU
======================================================================
[32m[I 2026-01-15 23:53:53,038][0m A new study created in memory with name: no-name-3d525625-8fb9-4ebe-b4a9-7ec5b3f19532[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:53,041][0m Trial 0 failed with parameters: {'input_size': 24, 'hidden_size': 128, 'num_layers': 2, 'batch_size': 32} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
[33m[W 2026-01-15 23:53:53,041][0m Trial 0 failed with value None.[0m
Error training GRU: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
Step: 37 | Action: 2 (GRU) | Reward: -1.000000

======================================================================
Step 9/10: Training LSTM
======================================================================
[32m[I 2026-01-15 23:53:53,058][0m A new study created in memory with name: no-name-614ff281-7a51-421d-a7a0-b1d112fdbbeb[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:53,060][0m Trial 0 failed with parameters: {'input_size': 96, 'hidden_size': 64, 'num_layers': 3, 'batch_size': 32} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
[33m[W 2026-01-15 23:53:53,060][0m Trial 0 failed with value None.[0m
Error training LSTM: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
Step: 38 | Action: 3 (LSTM) | Reward: -1.000000

======================================================================
Step 10/10: Training KAN
======================================================================
[32m[I 2026-01-15 23:53:53,077][0m A new study created in memory with name: no-name-279da23c-3ffe-4138-aab2-bece07f48147[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py:625: UserWarning: ignoring learning rate passed in optimizer_kwargs, using the model's learning rate
  warnings.warn(
[33m[W 2026-01-15 23:53:53,098][0m Trial 0 failed with parameters: {'input_size': 48, 'hidden_size': 256, 'grid_size': 15, 'batch_size': 16, 'spline_order': 2, 'scaler_type': 'minmax'} because of the following error: MisconfigurationException('The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}').[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 602, in _fit
    trainer.fit(model, datamodule=datamodule)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 584, in fit
    call._call_and_handle_interrupt(
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 630, in _fit_impl
    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1053, in _run
    self.strategy.setup(self)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 159, in setup
    self.setup_optimizers(trainer)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 190, in _init_optimizers_and_lr_schedulers
    _configure_schedulers_automatic_opt(lr_schedulers, monitor)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 278, in _configure_schedulers_automatic_opt
    raise MisconfigurationException(
lightning_fabric.utilities.exceptions.MisconfigurationException: The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}
[33m[W 2026-01-15 23:53:53,098][0m Trial 0 failed with value None.[0m
Error training KAN: The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}
Step: 39 | Action: 4 (KAN) | Reward: -1.000000
HenÃ¼z sonuÃ§ yok!

=== Episode 5/5 ===

======================================================================
Environment Reset
======================================================================


======================================================================
Step 1/10: Training TimesNet
======================================================================
[32m[I 2026-01-15 23:53:53,115][0m A new study created in memory with name: no-name-c828d6f9-3b7f-4b0a-b63f-6af022f48083[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
`Trainer(val_check_interval=1)` was configured so validation will run after every batch.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py:625: UserWarning: ignoring learning rate passed in optimizer_kwargs, using the model's learning rate
  warnings.warn(
[33m[W 2026-01-15 23:53:53,137][0m Trial 0 failed with parameters: {'input_size': 72, 'hidden_size': 64, 'dropout': 0.31146232264606416, 'conv_hidden_size': 16, 'top_k': 5, 'num_kernels': 7, 'encoder_layers': 2, 'batch_size': 32, 'windows_batch_size': 1024} because of the following error: TypeError("'<=' not supported between instances of 'float' and 'Float'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 602, in _fit
    trainer.fit(model, datamodule=datamodule)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 584, in fit
    call._call_and_handle_interrupt(
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 630, in _fit_impl
    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1053, in _run
    self.strategy.setup(self)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 159, in setup
    self.setup_optimizers(trainer)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 180, in _init_optimizers_and_lr_schedulers
    optim_conf = call._call_lightning_module_hook(model.trainer, "configure_optimizers", pl_module=model)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 629, in configure_optimizers
    optimizer = self.optimizer(params=self.parameters(), **optimizer_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/optim/adadelta.py", line 44, in __init__
    if not 0.0 <= lr:
           ^^^^^^^^^
TypeError: '<=' not supported between instances of 'float' and 'Float'
[33m[W 2026-01-15 23:53:53,137][0m Trial 0 failed with value None.[0m
Error training TimesNet: '<=' not supported between instances of 'float' and 'Float'
Step: 40 | Action: 0 (TimesNet) | Reward: -1.000000

======================================================================
Step 2/10: Training VanillaTransformer
======================================================================
[32m[I 2026-01-15 23:53:53,154][0m A new study created in memory with name: no-name-d4bb3d9e-c0f4-4d7b-a21b-b25e238fc8e7[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:53,163][0m Trial 0 failed with parameters: {'input_size': 96, 'nhead': 2, 'num_encoder_layers': 1, 'num_decoder_layers': 1, 'batch_size': 64, 'scaler_type': 'robust'} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'
[33m[W 2026-01-15 23:53:53,163][0m Trial 0 failed with value None.[0m
Error training VanillaTransformer: Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'
Step: 41 | Action: 1 (VanillaTransformer) | Reward: -1.000000

======================================================================
Step 3/10: Training GRU
======================================================================
[32m[I 2026-01-15 23:53:53,181][0m A new study created in memory with name: no-name-f131b879-7dc1-4e2d-8349-5d046a7e9567[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:53,183][0m Trial 0 failed with parameters: {'input_size': 48, 'hidden_size': 32, 'num_layers': 2, 'batch_size': 32} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
[33m[W 2026-01-15 23:53:53,183][0m Trial 0 failed with value None.[0m
Error training GRU: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
Step: 42 | Action: 2 (GRU) | Reward: -1.000000

======================================================================
Step 4/10: Training LSTM
======================================================================
[32m[I 2026-01-15 23:53:53,200][0m A new study created in memory with name: no-name-bd599d15-bd3f-47a8-8af1-40dcd8181aaa[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:53,205][0m Trial 0 failed with parameters: {'input_size': 72, 'hidden_size': 256, 'num_layers': 3, 'batch_size': 32} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
[33m[W 2026-01-15 23:53:53,205][0m Trial 0 failed with value None.[0m
Error training LSTM: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
Step: 43 | Action: 3 (LSTM) | Reward: -1.000000

======================================================================
Step 5/10: Training KAN
======================================================================
[32m[I 2026-01-15 23:53:53,221][0m A new study created in memory with name: no-name-e88a2159-137b-4cd1-bddb-bc9ea8698ef6[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py:625: UserWarning: ignoring learning rate passed in optimizer_kwargs, using the model's learning rate
  warnings.warn(
[33m[W 2026-01-15 23:53:53,239][0m Trial 0 failed with parameters: {'input_size': 96, 'hidden_size': 128, 'grid_size': 15, 'batch_size': 32, 'spline_order': 2, 'scaler_type': 'minmax'} because of the following error: MisconfigurationException('The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}').[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 602, in _fit
    trainer.fit(model, datamodule=datamodule)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 584, in fit
    call._call_and_handle_interrupt(
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 630, in _fit_impl
    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1053, in _run
    self.strategy.setup(self)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 159, in setup
    self.setup_optimizers(trainer)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 190, in _init_optimizers_and_lr_schedulers
    _configure_schedulers_automatic_opt(lr_schedulers, monitor)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 278, in _configure_schedulers_automatic_opt
    raise MisconfigurationException(
lightning_fabric.utilities.exceptions.MisconfigurationException: The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}
[33m[W 2026-01-15 23:53:53,240][0m Trial 0 failed with value None.[0m
Error training KAN: The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}
Step: 44 | Action: 4 (KAN) | Reward: -1.000000

======================================================================
Step 6/10: Training TimesNet
======================================================================
[32m[I 2026-01-15 23:53:53,259][0m A new study created in memory with name: no-name-6c2d31fb-7a3b-4c3d-9470-f5ac66d041ee[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
`Trainer(val_check_interval=1)` was configured so validation will run after every batch.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py:625: UserWarning: ignoring learning rate passed in optimizer_kwargs, using the model's learning rate
  warnings.warn(
[33m[W 2026-01-15 23:53:53,300][0m Trial 0 failed with parameters: {'input_size': 72, 'hidden_size': 64, 'dropout': 0.4389982250495324, 'conv_hidden_size': 32, 'top_k': 6, 'num_kernels': 6, 'encoder_layers': 4, 'batch_size': 64, 'windows_batch_size': 128} because of the following error: TypeError("'<=' not supported between instances of 'float' and 'Float'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 602, in _fit
    trainer.fit(model, datamodule=datamodule)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 584, in fit
    call._call_and_handle_interrupt(
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 630, in _fit_impl
    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1053, in _run
    self.strategy.setup(self)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 159, in setup
    self.setup_optimizers(trainer)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 180, in _init_optimizers_and_lr_schedulers
    optim_conf = call._call_lightning_module_hook(model.trainer, "configure_optimizers", pl_module=model)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 629, in configure_optimizers
    optimizer = self.optimizer(params=self.parameters(), **optimizer_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/optim/adadelta.py", line 44, in __init__
    if not 0.0 <= lr:
           ^^^^^^^^^
TypeError: '<=' not supported between instances of 'float' and 'Float'
[33m[W 2026-01-15 23:53:53,301][0m Trial 0 failed with value None.[0m
Error training TimesNet: '<=' not supported between instances of 'float' and 'Float'
Step: 45 | Action: 0 (TimesNet) | Reward: -1.000000

======================================================================
Step 7/10: Training VanillaTransformer
======================================================================
[32m[I 2026-01-15 23:53:53,317][0m A new study created in memory with name: no-name-351775bf-5cab-47f2-9d21-0d7fa900a6fe[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:53,325][0m Trial 0 failed with parameters: {'input_size': 48, 'nhead': 8, 'num_encoder_layers': 1, 'num_decoder_layers': 4, 'batch_size': 128, 'scaler_type': 'robust'} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'
[33m[W 2026-01-15 23:53:53,325][0m Trial 0 failed with value None.[0m
Error training VanillaTransformer: Trainer.__init__() got an unexpected keyword argument 'num_encoder_layers'
Step: 46 | Action: 1 (VanillaTransformer) | Reward: -1.000000

======================================================================
Step 8/10: Training GRU
======================================================================
[32m[I 2026-01-15 23:53:53,343][0m A new study created in memory with name: no-name-c86297c2-2bb3-4a54-badf-d70c64248461[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:53,345][0m Trial 0 failed with parameters: {'input_size': 72, 'hidden_size': 32, 'num_layers': 3, 'batch_size': 64} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
[33m[W 2026-01-15 23:53:53,346][0m Trial 0 failed with value None.[0m
Error training GRU: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
Step: 47 | Action: 2 (GRU) | Reward: -1.000000

======================================================================
Step 9/10: Training LSTM
======================================================================
[32m[I 2026-01-15 23:53:53,362][0m A new study created in memory with name: no-name-830dee3a-f79f-4890-9d03-83c38baa85b7[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
[33m[W 2026-01-15 23:53:53,366][0m Trial 0 failed with parameters: {'input_size': 96, 'hidden_size': 256, 'num_layers': 1, 'batch_size': 16} because of the following error: TypeError("Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'").[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 601, in _fit
    trainer = pl.Trainer(**model.trainer_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
TypeError: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
[33m[W 2026-01-15 23:53:53,366][0m Trial 0 failed with value None.[0m
Error training LSTM: Trainer.__init__() got an unexpected keyword argument 'encoder_num_layers'
Step: 48 | Action: 3 (LSTM) | Reward: -1.000000

======================================================================
Step 10/10: Training KAN
======================================================================
[32m[I 2026-01-15 23:53:53,383][0m A new study created in memory with name: no-name-84cfdb7e-4845-43fb-aece-1ba4177c7c89[0m
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:400: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
Seed set to 26
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
[34m[1mwandb[0m: [33mWARNING[0m `wandb.require('service')` is a no-op as it is now the default behavior.
/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py:625: UserWarning: ignoring learning rate passed in optimizer_kwargs, using the model's learning rate
  warnings.warn(
[33m[W 2026-01-15 23:53:53,403][0m Trial 0 failed with parameters: {'input_size': 72, 'hidden_size': 128, 'grid_size': 15, 'batch_size': 128, 'spline_order': 4, 'scaler_type': 'standard'} because of the following error: MisconfigurationException('The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}').[0m
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 310, in objective
    model = self._fit_model(
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_auto.py", line 347, in _fit_model
    model = model.fit(
            ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 1924, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/neuralforecast/common/_base_model.py", line 602, in _fit
    trainer.fit(model, datamodule=datamodule)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 584, in fit
    call._call_and_handle_interrupt(
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 630, in _fit_impl
    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1053, in _run
    self.strategy.setup(self)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 159, in setup
    self.setup_optimizers(trainer)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 139, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 190, in _init_optimizers_and_lr_schedulers
    _configure_schedulers_automatic_opt(lr_schedulers, monitor)
  File "/usr/local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 278, in _configure_schedulers_automatic_opt
    raise MisconfigurationException(
lightning_fabric.utilities.exceptions.MisconfigurationException: The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}
[33m[W 2026-01-15 23:53:53,403][0m Trial 0 failed with value None.[0m
Error training KAN: The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used. For example: {"optimizer": optimizer, "lr_scheduler": {"scheduler": scheduler, "monitor": "your_loss"}}
Step: 49 | Action: 4 (KAN) | Reward: -1.000000
HenÃ¼z sonuÃ§ yok!

======================================================================
STATISTICS
======================================================================
Total Steps: 50
Best Action: 0 (TimesNet)
Action Counts: [10.0, 10.0, 10.0, 10.0, 10.0]
Mean Rewards: ['-1.000000', '-1.000000', '-1.000000', '-1.000000', '-1.000000']
Total Rewards: ['-10.000000', '-10.000000', '-10.000000', '-10.000000', '-10.000000']
======================================================================

â Agent saved: outputs/run_20260115_235348/agent.json

======================================================================
Training ended at 2026-01-15 23:53:53
All outputs saved to: outputs/run_20260115_235348
======================================================================
EÄitim tamamlandÄ±.
